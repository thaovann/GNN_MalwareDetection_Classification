{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. About data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CSV files in each directory:\n",
      "Data/Adware/*/*.csv: 104\n",
      "Data/Ransomware/*/*.csv: 101\n",
      "Data/Scareware/*/*.csv: 112\n",
      "Data/SMSmalware/*/*.csv: 109\n",
      "Data/Benign/*/*.csv: 1700\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "directories = [\n",
    "    \"Data/Adware/*/*.csv\",\n",
    "    \"Data/Ransomware/*/*.csv\",\n",
    "    \"Data/Scareware/*/*.csv\",\n",
    "    \"Data/SMSmalware/*/*.csv\",\n",
    "    \"Data/Benign/*/*.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "file_count = {}\n",
    "graph_data = []\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    file_count[directory] = len(file_paths)\n",
    "\n",
    "# in ra số application được sử dụng trong data\n",
    "print(\"Number of CSV files in each directory:\")\n",
    "for directory, count in file_count.items():\n",
    "    print(f\"{directory}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8034\n",
      "15220\n",
      "7\n",
      "1516438\n",
      "1853\n",
      "2829\n",
      "23099\n",
      "87628\n",
      "2067\n",
      "661\n",
      "158084\n",
      "254420\n",
      "1474\n",
      "892\n",
      "203766\n",
      "284560\n",
      "1334151\n",
      "1766484\n",
      "1699573\n",
      "1188208\n",
      "1389492\n",
      "646317\n",
      "1256260\n",
      "1382411\n",
      "1058972\n",
      "1141466\n",
      "527406\n",
      "718084\n",
      "807751\n",
      "787590\n",
      "622058\n",
      "107864\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5712\n",
      "5895\n",
      "1744955\n",
      "1244704\n",
      "230\n",
      "2070\n",
      "318678\n",
      "417126\n",
      "416899\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "31\n",
      "255580\n",
      "124160\n",
      "172693\n",
      "5711\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1852\n",
      "23097\n",
      "2827\n",
      "87626\n",
      "8719\n",
      "8233\n",
      "517\n",
      "44\n",
      "249637\n",
      "47186\n",
      "245638\n",
      "237868\n",
      "283740\n",
      "67537\n",
      "282042\n",
      "282377\n",
      "46\n",
      "Columns with the same value in all lines (except for Source IP and Destination IP):\n",
      "[' Protocol', 'Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags', 'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count', ' ECE Flag Count', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "directories = [\n",
    "    \"Data/Adware/*/*.csv\",\n",
    "    \"Data/Ransomware/*/*.csv\",\n",
    "    \"Data/Scareware/*/*.csv\",\n",
    "    \"Data/SMSmalware/*/*.csv\",\n",
    "    \"Data/Benign/*/*.csv\",\n",
    "]\n",
    "\n",
    "file_count = {}\n",
    "graph_data = []\n",
    "\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    file_count[directory] = len(file_paths)\n",
    "    for file_path in file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        graph_data.append(data)\n",
    "\n",
    "df = pd.concat(graph_data, ignore_index=True)\n",
    "\n",
    "same_value_columns = []\n",
    "for column in df.columns:\n",
    "    if column not in [\n",
    "        \"Source IP\",\n",
    "        \"Destination IP\",\n",
    "        \"Flow ID\",\n",
    "        \" Source Port\",\n",
    "        \" Destination Port\",\n",
    "        \" Timestamp\",\n",
    "    ]:\n",
    "        unique_values = df[column].unique()\n",
    "        print(len(unique_values))\n",
    "        if len(unique_values) <= 10:\n",
    "            same_value_columns.append(column)\n",
    "\n",
    "print(\n",
    "    \"Columns with the same value in all lines (except for Source IP and Destination IP):\"\n",
    ")\n",
    "print(same_value_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import ipaddress\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "\n",
    "def preprocessing_data(csv_file):\n",
    "\n",
    "    columns_to_drop = [\n",
    "        \" ECE Flag Count\",\n",
    "        \" Fwd Avg Packets/Bulk \",\n",
    "        \" Fwd Avg Bulk Rate\",\n",
    "        \" Bwd Avg Bytes/Bulk\",\n",
    "        \" Bwd Avg Packets/Bulk\",\n",
    "        \" Bwd Avg Bulk Rate\",\n",
    "        \"Flow ID\",\n",
    "        \" Source Port\",\n",
    "        \" Destination Port\",\n",
    "        \" Timestamp\",\n",
    "        \" Protocol\",\n",
    "        \"Fwd PSH Flags\",\n",
    "        \" Bwd PSH Flags\",\n",
    "        \" Fwd URG Flags\",\n",
    "        \" Bwd URG Flags\",\n",
    "        \"FIN Flag Count\",\n",
    "        \" SYN Flag Count\",\n",
    "        \" RST Flag Count\",\n",
    "        \" PSH Flag Count\",\n",
    "        \" ACK Flag Count\",\n",
    "        \" URG Flag Count\",\n",
    "        \" CWE Flag Count\",\n",
    "        \" ECE Flag Count\",\n",
    "        \"Fwd Avg Bytes/Bulk\",\n",
    "        \" Fwd Avg Packets/Bulk\",\n",
    "        \" Fwd Avg Bulk Rate\",\n",
    "        \" Bwd Avg Bytes/Bulk\",\n",
    "        \" Bwd Avg Packets/Bulk\",\n",
    "        \"Bwd Avg Bulk Rate\",\n",
    "    ]\n",
    "    data = pd.read_csv(csv_file, usecols=lambda column: column not in columns_to_drop)\n",
    "\n",
    "    data.columns = data.columns.str.strip()\n",
    "\n",
    "    def is_valid_ipv4(ip):\n",
    "        try:\n",
    "            ipaddress.IPv4Address(ip)\n",
    "            return True\n",
    "        except ipaddress.AddressValueError:\n",
    "            return False\n",
    "\n",
    "    valid_ip_mask = data.apply(\n",
    "        lambda row: is_valid_ipv4(row[\"Source IP\"])\n",
    "        and is_valid_ipv4(row[\"Destination IP\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    data = data[valid_ip_mask]\n",
    "\n",
    "    data = data.dropna(subset=[\"Source IP\", \"Destination IP\"])\n",
    "\n",
    "    def ip_address(ip):\n",
    "        ip_integer = int(ipaddress.IPv4Address(ip))\n",
    "        return ip_integer\n",
    "\n",
    "    data[\"Source IP\"] = data[\"Source IP\"].apply(lambda i: ip_address(i))\n",
    "    data[\"Destination IP\"] = data[\"Destination IP\"].apply(lambda i: ip_address(i))\n",
    "    data = data.dropna()\n",
    "\n",
    "    def encode_label(label):\n",
    "        if \"SMSMALWARE\" in label:\n",
    "            return 4\n",
    "\n",
    "    data[\"Label\"] = data[\"Label\"].apply(lambda i: encode_label(i))\n",
    "    graph_label = [3]\n",
    "\n",
    "    numerical_columns = data.select_dtypes(include=[float, int]).columns.difference(\n",
    "        [\"Source IP\", \"Destination IP\", \"Label\"]\n",
    "    )\n",
    "    data[numerical_columns] = normalize_data(data[numerical_columns])\n",
    "\n",
    "    return data, graph_label\n",
    "\n",
    "\n",
    "def normalize_data(data, exclude_columns=[]):\n",
    "    scaler = MaxAbsScaler()\n",
    "    columns_to_normalize = data.columns.difference(exclude_columns)\n",
    "    data_to_normalize = data[columns_to_normalize].copy()\n",
    "\n",
    "    scaled_data = scaler.fit_transform(data_to_normalize)\n",
    "\n",
    "    return scaled_data\n",
    "\n",
    "\n",
    "def create_flow_graph_from_csv(data, idx, graph_label):\n",
    "\n",
    "    end_point = data[\"Source IP\"].astype(str) + data[\"Destination IP\"].astype(str)\n",
    "    nodes_list = end_point.unique()\n",
    "    num_nodes = len(nodes_list)\n",
    "\n",
    "    # Create edge_index using mapped indices\n",
    "    edges_list = data[[\"Source IP\", \"Destination IP\"]].values.tolist()\n",
    "    edge_index = np.array(edges_list).T\n",
    "\n",
    "    edge_attr_list = []\n",
    "    for edge in edges_list:\n",
    "        src_ip = edge[0]\n",
    "        dst_ip = edge[1]\n",
    "\n",
    "        # Lọc dữ liệu theo cạnh hiện tại\n",
    "        edge_data = data[\n",
    "            (data[\"Source IP\"] == src_ip) & (data[\"Destination IP\"] == dst_ip)\n",
    "        ]\n",
    "        if not edge_data.empty:\n",
    "            edge_attr = []\n",
    "            for feature in edge_data.columns:\n",
    "                if feature not in [\"Source IP\", \"Destination IP\", \"Label\"]:\n",
    "                    values = edge_data[feature]\n",
    "\n",
    "                    # Tính trung bình\n",
    "                    if not np.isnan(np.nanmean(values)):\n",
    "                        mean_value = np.nanmean(values)\n",
    "                    else:\n",
    "                        mean_value = 0\n",
    "\n",
    "                    # Tính độ lệch chuẩn\n",
    "                    if not np.isnan(np.nanstd(values)):\n",
    "                        std_value = np.nanstd(values)\n",
    "                    else:\n",
    "                        std_value = 0\n",
    "\n",
    "                    # Tính độ lệch\n",
    "                    if not np.isnan(values.skew()):\n",
    "                        skew_value = values.skew()\n",
    "                    else:\n",
    "                        skew_value = 0\n",
    "\n",
    "                    # Tính độ nhọn\n",
    "                    if not np.isnan(values.kurtosis()):\n",
    "                        kurtosis_value = values.kurtosis()\n",
    "                    else:\n",
    "                        kurtosis_value = 0\n",
    "\n",
    "                    # Tính giá trị trung vị\n",
    "                    if not np.isnan(np.nanmedian(values)):\n",
    "                        median_value = np.nanmedian(values)\n",
    "                    else:\n",
    "                        median_value = 0\n",
    "\n",
    "                    edge_attr.extend(\n",
    "                        [\n",
    "                            mean_value,\n",
    "                            std_value,\n",
    "                            skew_value,\n",
    "                            kurtosis_value,\n",
    "                            median_value,\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "            edge_attr_list.append(edge_attr)\n",
    "    node_attr = torch.zeros(num_nodes, 375)\n",
    "    edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
    "    label = torch.tensor(graph_label)\n",
    "    flow_graph = Data(x=node_attr, edge_index=edge_index, edge_attr=edge_attr, y=label)\n",
    "    torch.save(flow_graph, f\"graph/graph{idx}.pt\")\n",
    "    return flow_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "directories = [\n",
    "    \"Data/Scareware/*/*.csv\",\n",
    "    \"Data/Benign/*/*.csv\",\n",
    "    \"Data/Ransomware/*/*.csv\",\n",
    "    \"Data/Adware/*/*.csv\",\n",
    "    \"Data/SMSmalware/*/*.csv\",\n",
    "]\n",
    "\n",
    "file_count = {}\n",
    "graph_data = []\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    file_count[directory] = len(file_paths)\n",
    "\n",
    "all_graphs = []\n",
    "graph_labels = []\n",
    "idx = 1\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    for file in file_paths:\n",
    "        graph_data, graph_label = preprocessing_data(file)\n",
    "        flow_graph = create_flow_graph_from_csv(graph_data, idx, graph_label)\n",
    "        # print(idx)\n",
    "        # print(graph_data)\n",
    "        # print(graph_label)\n",
    "    idx = idx + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
