{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import ipaddress\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "\n",
    "def preprocessing_data(csv_file):\n",
    "\n",
    "    # drop features that all of flow have value equal to zero\n",
    "\n",
    "    columns_to_drop = [\n",
    "        \" ECE Flag Count\",\n",
    "        \" Fwd Avg Packets/Bulk \",\n",
    "        \" Fwd Avg Bulk Rate\",\n",
    "        \" Bwd Avg Bytes/Bulk\",\n",
    "        \" Bwd Avg Packets/Bulk\",\n",
    "        \" Bwd Avg Bulk Rate\",\n",
    "        \"Flow ID\",\n",
    "        \" Source Port\",\n",
    "        \" Destination Port\",\n",
    "        \" Timestamp\",\n",
    "    ]\n",
    "    data = pd.read_csv(csv_file, usecols=lambda column: column not in columns_to_drop)\n",
    "    # Bỏ dấu cách trước tên các trường\n",
    "    data.columns = data.columns.str.strip()\n",
    "\n",
    "    # loại bỏ dòng mà có địa chỉ ip không hợp lệ\n",
    "    def is_valid_ipv4(ip):\n",
    "        try:\n",
    "            ipaddress.IPv4Address(ip)\n",
    "            return True\n",
    "        except ipaddress.AddressValueError:\n",
    "            return False\n",
    "\n",
    "    # Lọc dữ liệu dựa trên địa chỉ IP không hợp lệ\n",
    "    valid_ip_mask = data.apply(\n",
    "        lambda row: is_valid_ipv4(row[\"Source IP\"])\n",
    "        and is_valid_ipv4(row[\"Destination IP\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    data = data[valid_ip_mask]\n",
    "\n",
    "    # Filter out rows with None values (invalid IP addresses)\n",
    "    data = data.dropna(subset=[\"Source IP\", \"Destination IP\", \"Label\"])\n",
    "\n",
    "    def ip_address(ip):\n",
    "        ip_integer = int(ipaddress.IPv4Address(ip))\n",
    "        return ip_integer\n",
    "\n",
    "    data[\"Source IP\"] = data[\"Source IP\"].apply(lambda i: ip_address(i))\n",
    "    data[\"Destination IP\"] = data[\"Destination IP\"].apply(lambda i: ip_address(i))\n",
    "    data = data.dropna()\n",
    "\n",
    "    # if data[] is None delete data[]\n",
    "    # encode label for binary classification task\n",
    "    def encode_label(label):\n",
    "        if label == \"BENIGN\":\n",
    "            return 0\n",
    "        elif \"ADWARE\" in label:\n",
    "            return 1\n",
    "        elif \"RANSOMWARE\" in label:\n",
    "            return 2\n",
    "        elif \"SCAREWARE\" in label:\n",
    "            return 3\n",
    "        elif \"SMSMALWARE\" in label:\n",
    "            return 4\n",
    "\n",
    "    data[\"Label\"] = data[\"Label\"].apply(lambda i: encode_label(i))\n",
    "    graph_label = data[\"Label\"].unique()\n",
    "\n",
    "    numerical_columns = data.select_dtypes(include=[float, int]).columns.difference(\n",
    "        [\"Source IP\", \"Destination IP\", \"Label\"]\n",
    "    )\n",
    "    data[numerical_columns] = normalize_data(data[numerical_columns])\n",
    "\n",
    "    return data, graph_label\n",
    "\n",
    "\n",
    "def normalize_data(data, exclude_columns=[]):\n",
    "    scaler = MaxAbsScaler()\n",
    "    columns_to_normalize = data.columns.difference(exclude_columns)\n",
    "    data_to_normalize = data[columns_to_normalize].copy()\n",
    "\n",
    "    scaled_data = scaler.fit_transform(data_to_normalize)\n",
    "\n",
    "    return scaled_data\n",
    "\n",
    "\n",
    "def create_flow_graph_from_csv(data, idx, graph_label):\n",
    "\n",
    "\n",
    "    end_point = data[\"Source IP\"].astype(str) + data[\"Destination IP\"].astype(str)\n",
    "\n",
    "    nodes_list = end_point.unique()\n",
    "\n",
    "    num_nodes = len(nodes_list)\n",
    "\n",
    "\n",
    "    # Create edge_index using mapped indices\n",
    "\n",
    "    edges_list = data[[\"Source IP\", \"Destination IP\"]].values.tolist()\n",
    "\n",
    "    edge_index = np.array(edges_list).T\n",
    "\n",
    "\n",
    "    edge_attr_list = []\n",
    "\n",
    "    for edge in edges_list:\n",
    "\n",
    "        src_ip = edge[0]\n",
    "\n",
    "        dst_ip = edge[1]\n",
    "\n",
    "\n",
    "        # Lọc dữ liệu theo cạnh hiện tại\n",
    "\n",
    "        edge_data = data[\n",
    "\n",
    "            (data[\"Source IP\"] == src_ip) & (data[\"Destination IP\"] == dst_ip)\n",
    "\n",
    "        ]\n",
    "\n",
    "        if not edge_data.empty:\n",
    "\n",
    "            edge_attr = []\n",
    "\n",
    "            for feature in edge_data.columns:\n",
    "\n",
    "                if feature not in [\"Source IP\", \"Destination IP\", \"Label\"]:\n",
    "\n",
    "                    values = edge_data[feature]\n",
    "\n",
    "                    if not np.isnan(np.nanmean(values)):\n",
    "\n",
    "                        mean_value = np.nanmean(values)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        mean_value = 0\n",
    "\n",
    "\n",
    "                    # Tính độ lệch chuẩn\n",
    "\n",
    "                    if not np.isnan(np.nanstd(values)):\n",
    "\n",
    "                        std_value = np.nanstd(values)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        std_value = 0\n",
    "\n",
    "\n",
    "                    # Tính độ lệch\n",
    "\n",
    "                    if not np.isnan(values.skew()):\n",
    "\n",
    "                        skew_value = values.skew()\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        skew_value = 0\n",
    "\n",
    "\n",
    "                    # Tính độ nhọn\n",
    "\n",
    "                    if not np.isnan(values.kurtosis()):\n",
    "\n",
    "                        kurtosis_value = values.kurtosis()\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        kurtosis_value = 0\n",
    "\n",
    "\n",
    "                    # Tính giá trị trung vị\n",
    "\n",
    "                    if not np.isnan(np.nanmedian(values)):\n",
    "\n",
    "                        median_value = np.nanmedian(values)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        median_value = 0\n",
    "\n",
    "\n",
    "                    edge_attr.extend(\n",
    "\n",
    "                        [\n",
    "\n",
    "                            mean_value,\n",
    "\n",
    "                            std_value,\n",
    "\n",
    "                            skew_value,\n",
    "\n",
    "                            kurtosis_value,\n",
    "\n",
    "                            median_value,\n",
    "\n",
    "                        ]\n",
    "\n",
    "                    )\n",
    "\n",
    "\n",
    "            edge_attr_list.append(edge_attr)\n",
    "\n",
    "    node_attr = torch.zeros(num_nodes, 375)\n",
    "\n",
    "    edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
    "\n",
    "    label = torch.tensor(graph_label)\n",
    "\n",
    "    flow_graph = Data(x=node_attr, edge_index=edge_index, edge_attr=edge_attr, y=label)\n",
    "\n",
    "    torch.save(flow_graph, f\"graph_adware/adware{idx}.pt\")\n",
    "\n",
    "    return flow_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n",
      "2\n",
      "[1]\n",
      "3\n",
      "[1]\n",
      "4\n",
      "[1]\n",
      "5\n",
      "[1]\n",
      "6\n",
      "[1]\n",
      "7\n",
      "[1]\n",
      "8\n",
      "[1]\n",
      "9\n",
      "[1]\n",
      "10\n",
      "[1]\n",
      "11\n",
      "[1]\n",
      "12\n",
      "[1]\n",
      "13\n",
      "[1]\n",
      "14\n",
      "[1]\n",
      "15\n",
      "[1]\n",
      "16\n",
      "[1]\n",
      "17\n",
      "[1]\n",
      "18\n",
      "[1]\n",
      "19\n",
      "[1]\n",
      "20\n",
      "[1]\n",
      "21\n",
      "[1]\n",
      "22\n",
      "[1]\n",
      "23\n",
      "[1]\n",
      "24\n",
      "[1]\n",
      "25\n",
      "[1]\n",
      "26\n",
      "[1]\n",
      "27\n",
      "[1]\n",
      "28\n",
      "[1]\n",
      "29\n",
      "[1]\n",
      "30\n",
      "[1]\n",
      "31\n",
      "[1]\n",
      "32\n",
      "[1]\n",
      "33\n",
      "[1]\n",
      "34\n",
      "[1]\n",
      "35\n",
      "[1]\n",
      "36\n",
      "[1]\n",
      "37\n",
      "[1]\n",
      "38\n",
      "[1]\n",
      "39\n",
      "[1]\n",
      "40\n",
      "[1]\n",
      "41\n",
      "[1]\n",
      "42\n",
      "[1]\n",
      "43\n",
      "[1]\n",
      "44\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "directories = [\n",
    "    \"Data/Adware/*/*.csv\",\n",
    "]\n",
    "\n",
    "file_count = {}\n",
    "graph_data = []\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    file_count[directory] = len(file_paths)\n",
    "\n",
    "all_graphs = []\n",
    "graph_labels = []\n",
    "idx = 1\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    for file in file_paths:\n",
    "        if idx > 0:\n",
    "            graph_data, graph_label = preprocessing_data(file)\n",
    "            flow_graph = create_flow_graph_from_csv(graph_data, idx, graph_label)\n",
    "            print(idx)\n",
    "            print(graph_label)\n",
    "        idx = idx + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
