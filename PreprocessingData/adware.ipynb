{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import ipaddress\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "\n",
    "def preprocessing_data(csv_file):\n",
    "\n",
    "    # drop features that all of flow have value equal to zero\n",
    "\n",
    "    columns_to_drop = [\n",
    "        \"Flow ID\",\n",
    "        \" Source Port\",\n",
    "        \" Destination Port\",\n",
    "        \" Timestamp\",\n",
    "        \" Protocol\",\n",
    "        \"Fwd PSH Flags\",\n",
    "        \" Bwd PSH Flags\",\n",
    "        \" Fwd URG Flags\",\n",
    "        \" Bwd URG Flags\",\n",
    "        \"FIN Flag Count\",\n",
    "        \" SYN Flag Count\",\n",
    "        \" RST Flag Count\",\n",
    "        \" PSH Flag Count\",\n",
    "        \" ACK Flag Count\",\n",
    "        \" URG Flag Count\",\n",
    "        \" CWE Flag Count\",\n",
    "        \" ECE Flag Count\",\n",
    "        \"Fwd Avg Bytes/Bulk\",\n",
    "        \" Fwd Avg Packets/Bulk\",\n",
    "        \" Fwd Avg Bulk Rate\",\n",
    "        \" Bwd Avg Bytes/Bulk\",\n",
    "        \" Bwd Avg Packets/Bulk\",\n",
    "        \"Bwd Avg Bulk Rate\",\n",
    "    ]\n",
    "    data = pd.read_csv(csv_file, usecols=lambda column: column not in columns_to_drop)\n",
    "    # Bỏ dấu cách trước tên các trường\n",
    "    data.columns = data.columns.str.strip()\n",
    "\n",
    "    # loại bỏ dòng mà có địa chỉ ip không hợp lệ\n",
    "    def is_valid_ipv4(ip):\n",
    "        try:\n",
    "            ipaddress.IPv4Address(ip)\n",
    "            return True\n",
    "        except ipaddress.AddressValueError:\n",
    "            return False\n",
    "\n",
    "    # Lọc dữ liệu dựa trên địa chỉ IP không hợp lệ\n",
    "    valid_ip_mask = data.apply(\n",
    "        lambda row: is_valid_ipv4(row[\"Source IP\"])\n",
    "        and is_valid_ipv4(row[\"Destination IP\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    data = data[valid_ip_mask]\n",
    "\n",
    "    # Filter out rows with None values (invalid IP addresses)\n",
    "    data = data.dropna(subset=[\"Source IP\", \"Destination IP\", \"Label\"])\n",
    "\n",
    "    def ip_address(ip):\n",
    "        ip_integer = int(ipaddress.IPv4Address(ip))\n",
    "        return ip_integer\n",
    "\n",
    "    data[\"Source IP\"] = data[\"Source IP\"].apply(lambda i: ip_address(i))\n",
    "    data[\"Destination IP\"] = data[\"Destination IP\"].apply(lambda i: ip_address(i))\n",
    "    data = data.dropna()\n",
    "\n",
    "    def encode_label(label):\n",
    "        if label == \"BENIGN\":\n",
    "            return 0\n",
    "        elif \"ADWARE\" in label:\n",
    "            return 1\n",
    "        elif \"RANSOMWARE\" in label:\n",
    "            return 2\n",
    "        elif \"SCAREWARE\" in label:\n",
    "            return 3\n",
    "        elif \"SMSMALWARE\" in label:\n",
    "            return 4\n",
    "\n",
    "    data[\"Label\"] = data[\"Label\"].apply(lambda i: encode_label(i))\n",
    "    graph_label = data[\"Label\"].unique()\n",
    "\n",
    "    # numerical_columns = data.select_dtypes(include=[float, int]).columns.difference(\n",
    "    #     [\"Source IP\", \"Destination IP\", \"Label\"]\n",
    "    # )\n",
    "    # data[numerical_columns] = normalize_data(data[numerical_columns])\n",
    "\n",
    "    return data, graph_label\n",
    "\n",
    "\n",
    "# def normalize_data(data, exclude_columns=[]):\n",
    "#     scaler = MaxAbsScaler()\n",
    "#     columns_to_normalize = data.columns.difference(exclude_columns)\n",
    "#     data_to_normalize = data[columns_to_normalize].copy()\n",
    "\n",
    "#     scaled_data = scaler.fit_transform(data_to_normalize)\n",
    "\n",
    "#     return scaled_data\n",
    "\n",
    "\n",
    "def create_flow_graph_from_csv(data, idx, graph_label):\n",
    "    end_point = data[\"Source IP\"].astype(str) + data[\"Destination IP\"].astype(str)\n",
    "    nodes_list = end_point.unique()\n",
    "    num_nodes = len(nodes_list)\n",
    "\n",
    "    # Create edge_index using mapped indices\n",
    "    edges_list = data[[\"Source IP\", \"Destination IP\"]].values.tolist()\n",
    "    edge_index = np.array(edges_list).T\n",
    "\n",
    "    edge_attr_list = []\n",
    "    for edge in edges_list:\n",
    "        src_ip = edge[0]\n",
    "        dst_ip = edge[1]\n",
    "        # Lọc dữ liệu theo cạnh hiện tại\n",
    "        edge_data = data[\n",
    "            (data[\"Source IP\"] == src_ip) & (data[\"Destination IP\"] == dst_ip)\n",
    "        ]\n",
    "\n",
    "        if not edge_data.empty:\n",
    "            edge_attr = []\n",
    "            for feature in edge_data.columns:\n",
    "                if feature not in [\"Source IP\", \"Destination IP\", \"Label\"]:\n",
    "                    values = edge_data[feature]\n",
    "                    if not np.isnan(np.nanmean(values)):\n",
    "                        mean_value = np.nanmean(values)\n",
    "                    else:\n",
    "                        mean_value = 0\n",
    "\n",
    "                    # ính độ lệch chuẩn\n",
    "                    if not np.isnan(np.nanstd(values)):\n",
    "                        std_value = np.nanstd(values)\n",
    "                    else:\n",
    "                        std_value = 0\n",
    "\n",
    "                    # Tính độ lệch\n",
    "                    if not np.isnan(values.skew()):\n",
    "                        skew_value = values.skew()\n",
    "                    else:\n",
    "                        skew_value = 0\n",
    "                    # Tính độ nhọn\n",
    "\n",
    "                    if not np.isnan(values.kurtosis()):\n",
    "                        kurtosis_value = values.kurtosis()\n",
    "                    else:\n",
    "                        kurtosis_value = 0\n",
    "                    if not np.isnan(np.nanmedian(values)):\n",
    "                        median_value = np.nanmedian(values)\n",
    "                    else:\n",
    "                        median_value = 0\n",
    "                    edge_attr.extend(\n",
    "                        [\n",
    "                            mean_value,\n",
    "                            std_value,\n",
    "                            skew_value,\n",
    "                            kurtosis_value,\n",
    "                            median_value,\n",
    "                        ]\n",
    "                    )\n",
    "            edge_attr_list.append(edge_attr)\n",
    "    node_attr = torch.zeros(num_nodes, 375)\n",
    "    edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
    "    label = torch.tensor(graph_label)\n",
    "    flow_graph = Data(x=node_attr, edge_index=edge_index, edge_attr=edge_attr, y=label)\n",
    "    torch.save(flow_graph, f\"graph_adware/adware{idx}.pt\")\n",
    "    return flow_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "[1]\n",
      "47\n",
      "[1]\n",
      "48\n",
      "[1]\n",
      "49\n",
      "[1]\n",
      "50\n",
      "[1]\n",
      "51\n",
      "[1]\n",
      "52\n",
      "[1]\n",
      "53\n",
      "[1]\n",
      "54\n",
      "[1]\n",
      "55\n",
      "[1]\n",
      "56\n",
      "[1]\n",
      "57\n",
      "[1]\n",
      "58\n",
      "[1]\n",
      "59\n",
      "[1]\n",
      "60\n",
      "[1]\n",
      "61\n",
      "[1]\n",
      "62\n",
      "[1]\n",
      "63\n",
      "[1]\n",
      "64\n",
      "[1]\n",
      "65\n",
      "[1]\n",
      "66\n",
      "[1]\n",
      "67\n",
      "[1]\n",
      "68\n",
      "[1]\n",
      "69\n",
      "[1]\n",
      "70\n",
      "[1]\n",
      "71\n",
      "[1]\n",
      "72\n",
      "[1]\n",
      "73\n",
      "[1]\n",
      "74\n",
      "[1]\n",
      "75\n",
      "[1]\n",
      "76\n",
      "[1]\n",
      "77\n",
      "[1]\n",
      "78\n",
      "[1]\n",
      "79\n",
      "[1]\n",
      "80\n",
      "[1]\n",
      "81\n",
      "[1]\n",
      "82\n",
      "[1]\n",
      "83\n",
      "[1]\n",
      "84\n",
      "[1]\n",
      "85\n",
      "[1]\n",
      "86\n",
      "[1]\n",
      "87\n",
      "[1]\n",
      "88\n",
      "[1]\n",
      "89\n",
      "[1]\n",
      "90\n",
      "[1]\n",
      "91\n",
      "[1]\n",
      "92\n",
      "[1]\n",
      "93\n",
      "[1]\n",
      "94\n",
      "[1]\n",
      "95\n",
      "[1]\n",
      "96\n",
      "[1]\n",
      "97\n",
      "[1]\n",
      "98\n",
      "[1]\n",
      "99\n",
      "[1]\n",
      "100\n",
      "[1]\n",
      "101\n",
      "[1]\n",
      "102\n",
      "[1]\n",
      "103\n",
      "[1]\n",
      "104\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "directories = [\n",
    "    \"Data/Adware/*/*.csv\",\n",
    "]\n",
    "\n",
    "file_count = {}\n",
    "graph_data = []\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    file_count[directory] = len(file_paths)\n",
    "\n",
    "all_graphs = []\n",
    "graph_labels = []\n",
    "idx = 1\n",
    "for directory in directories:\n",
    "    file_paths = glob.glob(directory)\n",
    "    for file in file_paths:\n",
    "        if idx > 45:\n",
    "            graph_data, graph_label = preprocessing_data(file)\n",
    "            flow_graph = create_flow_graph_from_csv(graph_data, idx, graph_label)\n",
    "            print(idx)\n",
    "            print(graph_label)\n",
    "        idx = idx + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
